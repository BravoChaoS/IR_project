{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 528, 1541, 1947, 1975\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "path_root = \"C:/BCSpace/study/ThisSemester/Information Retrieval/lab/lab2\"\n",
    "dir_source = \"mini_newsgroups_lab2\"\n",
    "dir_new = \"new_newsgroups_lab2\"  # new folder for the processed files\n",
    "path_source = os.path.join(path_root, dir_source)\n",
    "path_new = os.path.join(path_root, dir_new)\n",
    "terms_data = {}\n",
    "words_freq = {}\n",
    "inverted_index = {}\n",
    "file_list = [-1]\n",
    "file_id = {}\n",
    "file_dir = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 1: extract text and create new files\n",
    "def process_new_file():\n",
    "    if not os.path.exists(path_new):\n",
    "        os.mkdir(path_new)\n",
    "\n",
    "    for root, dirs, files in os.walk(path_source, topdown=True):\n",
    "        for dir_name in dirs:\n",
    "            if not os.path.exists(os.path.join(path_new, dir_name)):\n",
    "                os.mkdir(os.path.join(path_new, dir_name))\n",
    "\n",
    "    for root, dirs, files in os.walk(path_source, topdown=True):\n",
    "        for file_name in files:\n",
    "            f = open(os.path.join(root, file_name), 'r', errors='ignore')\n",
    "            text = f.read()\n",
    "            rtval = re.search(r\"Lines:\\s+(\\d+)\", text)\n",
    "            lines = int(rtval.group(1))\n",
    "            f.seek(0)\n",
    "            body = f.readlines()[-lines:]\n",
    "            # print(len(body))\n",
    "            f.close()\n",
    "            f = open(os.path.join(root, file_name).replace('mini', 'new'), 'w+')\n",
    "            for s in body:\n",
    "                f.write(s)\n",
    "            f.close()\n",
    "            \n",
    "\n",
    "process_new_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 528, 1541, 1947, 1975\n"
     ]
    }
   ],
   "source": [
    "# step 2: get files id\n",
    "def process_id():\n",
    "    for root, dirs, files in os.walk(path_source, topdown=True):\n",
    "        temp_list = []\n",
    "        for name in files:\n",
    "            temp_list.append(name)\n",
    "            file_dir[name] = os.path.join(root, name)\n",
    "            file_id[name] = root\n",
    "        if len(temp_list) <= 0:\n",
    "            continue\n",
    "        temp_list.sort()\n",
    "        file_list.extend(temp_list)\n",
    "\n",
    "    for index in range(len(file_list)):\n",
    "        file_id[file_list[index]] = index\n",
    "        \n",
    "\n",
    "process_id()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 528, 1541, 1947, 1975\n"
     ]
    }
   ],
   "source": [
    "# step 3, 4 and 5: create inverted index, output as file in \"path_root/inverted_index.csv\"\n",
    "def read_file(file_name):\n",
    "    f = open(file_name, 'r')\n",
    "    buffer = f.read()\n",
    "    f.close()\n",
    "    return buffer\n",
    "\n",
    "\n",
    "def process_inverted_index():\n",
    "    for root, dirs, files in os.walk(path_new, topdown=True):\n",
    "        for file_name in files:\n",
    "            doc = read_file(os.path.join(root, file_name))\n",
    "            doc = doc.lower()\n",
    "            word_tokenizer = nltk.RegexpTokenizer('[A-Za-z]+')\n",
    "            terms = word_tokenizer.tokenize(doc)\n",
    "            terms = set(terms)\n",
    "            for term in terms:\n",
    "                if term in terms_data:\n",
    "                    terms_data[term].add(file_id[file_name])\n",
    "                else:\n",
    "                    terms_data[term] = {file_id[file_name]}\n",
    "    for term, belongs in terms_data.items():\n",
    "        lst = list(belongs)\n",
    "        lst.sort()\n",
    "        inverted_index[term] = lst\n",
    "    f = open(os.path.join(path_root, 'inverted_index.csv'), 'w+')\n",
    "\n",
    "    sorted_inverted_index = sorted(inverted_index.items(), key=lambda v: v[0])\n",
    "    for word, l in sorted_inverted_index:\n",
    "        f.write(word + ',' + str(len(l)))\n",
    "        for it in l:\n",
    "            f.write(',' + str(it))\n",
    "        f.write('\\n')\n",
    "\n",
    "\n",
    "process_inverted_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 528, 1541, 1947, 1975\n"
     ]
    }
   ],
   "source": [
    "# query\n",
    "def merge_and(a, b):\n",
    "    temp_list = []\n",
    "    index_a = 0\n",
    "    index_b = 0\n",
    "    while index_a < len(a) or index_b < len(b):\n",
    "        if index_b == len(b) or (index_a < len(a) and a[index_a] < b[index_b]):\n",
    "            index_a = index_a + 1\n",
    "        elif index_a == len(a) or a[index_a] > b[index_b]:\n",
    "            index_b = index_b + 1\n",
    "        else:\n",
    "            temp_list.append(a[index_a])\n",
    "            index_a = index_a + 1\n",
    "            index_b = index_b + 1\n",
    "    return temp_list\n",
    "\n",
    "\n",
    "def merge_or(a, b):\n",
    "    temp_list = []\n",
    "    index_a = 0\n",
    "    index_b = 0\n",
    "    while index_a < len(a) or index_b < len(b):\n",
    "        if index_b == len(b) or (index_a < len(a) and a[index_a] <= b[index_b]):\n",
    "            temp_list.append(a[index_a])\n",
    "            index_a = index_a + 1\n",
    "        else:\n",
    "            temp_list.append(b[index_b])\n",
    "            index_b = index_b + 1\n",
    "    return temp_list\n",
    "\n",
    "\n",
    "def merge_not(a, b):\n",
    "    temp_list = []\n",
    "    index_a = 0\n",
    "    index_b = 0\n",
    "    while index_a < len(a) or index_b < len(b):\n",
    "        if index_b == len(b) or (index_a < len(a) and a[index_a] < b[index_b]):\n",
    "            temp_list.append(a[index_a])\n",
    "            index_a = index_a + 1\n",
    "        elif index_a == len(a) or a[index_a] > b[index_b]:\n",
    "            index_b = index_b + 1\n",
    "        else:\n",
    "            index_a = index_a + 1\n",
    "            index_b = index_b + 1\n",
    "    return temp_list\n",
    "\n",
    "\n",
    "def query(q):\n",
    "    q = q.lower()\n",
    "    word_tokenizer = nltk.RegexpTokenizer('[A-Za-z]+')\n",
    "    terms = word_tokenizer.tokenize(q)\n",
    "    ans = inverted_index[terms[0]]\n",
    "    for index in range(1, len(terms), 2):\n",
    "        if terms[index] == 'and':\n",
    "            ans = merge_and(ans, inverted_index[terms[index + 1]])\n",
    "        elif terms[index] == 'or':\n",
    "            ans = merge_or(ans, inverted_index[terms[index + 1]])\n",
    "        else:\n",
    "            ans = merge_not(ans, inverted_index[terms[index + 1]])\n",
    "    print(str(ans)[1:][:-1])\n",
    "\n",
    "\n",
    "query(\"answer not a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}